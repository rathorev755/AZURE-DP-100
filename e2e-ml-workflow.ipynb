{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Tutorial: Create production ML pipelines with Python SDK v2 (preview) in a Jupyter notebook\n"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives** - By the end of this two part tutorial, you should be able to use Azure Machine Learning (Azure ML) to productionize your ML project.\n",
        "\n",
        "This means you will be able to leverage the AzureML Python SDK to:\n",
        "\n",
        "- connect to your Azure ML workspace\n",
        "- create Azure ML data assets\n",
        "- create reusable Azure ML components\n",
        "- create, validate and run Azure ML pipelines\n",
        "- deploy the newly-trained model as an endpoint\n",
        "- call the Azure ML endpoint for inferencing"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "**Motivations** - This tutorial is intended to introduce Azure ML to data scientists who want to scale up or publish their ML projects. By completing a familiar end-to-end project, which starts by loading the data and ends by creating and calling an online inference endpoint, the user should become familiar with the core concepts of Azure ML and their most common usage. Each step of this tutorial can be modified or performed in other ways that might have security or scalability advantages. We will cover some of those in the Part II of this tutorial, however, we suggest the reader use the provide links in each section to learn more on each topic."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "**Requirements** - In order to benefit from this tutorial, you need to have:\n",
        "- basic understanding of Machine Learning projects workflow\n",
        "- an Azure subscription. If you don't have an Azure subscription, [create a free account](https://aka.ms/AMLFree) before you begin.\n",
        "- a working Azure ML workspace. A workspace can be created via Azure Portal, Azure CLI, or Python SDK. [Read more](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=python).\n",
        "- a Python environmnet\n",
        "- [installed Azure Machine Learning Python SDK v2](https://github.com/Azure/azureml-examples/blob/sdk-preview/sdk/setup.sh)"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this tutorial, you'll create an Azure ML pipeline to train a model for credit default prediction. The pipeline handles the data preparation, training and registering the trained model.  You'll then run the pipeline, deploy the model and use it.\n",
        "\n",
        "The image below shows the pipeline as you'll see it in the AzureML portal once submitted. It's a rather simple pipeline we'll use to walk you through the AzureML SDK v2.\n",
        "\n",
        "The two steps are first data preparation and second training. \n",
        "\n",
        "![Screenshot that shows the AML Pipeline](media/pipeline-overview.jpg \"Overview of the pipeline\")\n",
        "\n",
        "An AzureML pipeline that runs from local components, requires several dependent files. Fo better understanding of the project structure, we produce all these dependencies in the notebook cells. By the end of this tutorial, the project structure should look like:\n",
        "```\n",
        "e2e-ds-experience  \n",
        "    components\n",
        "        data_prep\n",
        "            data_prep.py \n",
        "        train\n",
        "            train.py\n",
        "            train.yml   \n",
        "    dependencies\n",
        "        conda.yaml\n",
        "    deploy\n",
        "        sample-request.json\n",
        "    media\n",
        "        metrics.jpg\n",
        "        pipeline-overview.jpg\n",
        "        user-logs.jpg\n",
        "    e2e-ml-workflow.ipynb\n",
        "```\n",
        "After running this notebook, you should be able to create the project direcetly in the IDE of your choice, instead.\n",
        "\n",
        "## Set up the pipeline resources\n",
        "\n",
        "The Azure ML framework can be used from CLI, Python SDK, or studio interface. In this example, you'll use the AzureML Python SDK v2 to create a pipeline. \n",
        "\n",
        "Before creating the pipeline, you'll set up the resources the pipeline will use:\n",
        "\n",
        "* The dataset for training\n",
        "* The software environment to run the pipeline\n",
        "\n",
        "## Connect to the workspace\n",
        "\n",
        "Before we dive in the code, you'll need to connect to your Azure ML workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
        "\n",
        "We are using `DefaultAzureCredential` to get access to workspace. \n",
        "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
        "\n",
        "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python).\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "import-mlclient",
        "gather": {
          "logged": 1747636429349
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find your Subscription ID:\n",
        "1. In the upper right Azure Machine Learning Studio toolbar, select your workspace name.\n",
        "1. At the bottom, select **View all properties in Azure Portal**\n",
        "1. Copy the value from Azure Portal into the code."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"fdec3bff-d6e2-4cf8-87b9-8439c441c1b7\",\n",
        "    resource_group_name=\"DP100\",\n",
        "    workspace_name=\"dp100demo\",\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "ml_client",
        "gather": {
          "logged": 1747636435771
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The result is a handler to the workspace that you'll use to manage other resources and jobs.\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (in the notebook below, that will happen during dataset registration).\n",
        "\n",
        "## Register data from an external url\n",
        "\n",
        "The data you use for training is usually in one of the locations below:\n",
        "\n",
        "* Local machine\n",
        "* Web\n",
        "* Big Data Storage services (for example, Azure Blob, Azure Data Lake Storage, SQL)\n",
        " \n",
        "Azure ML uses a [`Data`](https://docs.microsoft.com/azure/machine-learning/how-to-create-register-data-assets?tabs=Python-SDK) object to register a reusable definition of data, and consume data within a pipeline. In the section below, you'll consume some data from web url as one example. `Data` assets ets from other sources can be created as well."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "web_path = \"https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default%20of%20credit%20card%20clients.csv\"\n",
        "\n",
        "credit_data = Data(\n",
        "    name=\"creditcard_blob_csv_defaults\",\n",
        "    path=web_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Dataset for credit card defaults\",\n",
        "    tags={\"source_type\": \"web\", \"source\": \"AzureML examples blob\"},\n",
        "    version=\"1.0.0\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "name": "credit_data",
        "gather": {
          "logged": 1747636437625
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "This code just created a `Data` asset, it is ready to be consumed as an input by the pipeline that you'll define in the next sections. In addition, you can register the data to your workspace so it becomes reusable across pipelines.\n",
        "\n",
        "Registering the data asset will enable you to:\n",
        "\n",
        "* reuse and share the data asset in future pipelines\n",
        "* use versions to track the modification to the data asset\n",
        "* use the data asset from Azure ML designer, which is Azure ML's GUI for pipeline authoring\n",
        "\n",
        "Since this is the first time that you're making a call to the workspace, you may be asked to authenticate. Once the authentication is complete, you'll then see the dataset registration completion message."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "credit_data = ml_client.data.create_or_update(credit_data)\n",
        "print(\n",
        "    f\"Dataset with name {credit_data.name} was registered to workspace, the dataset version is {credit_data.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset with name creditcard_blob_csv_defaults was registered to workspace, the dataset version is 1.0.0\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "update-credit_data",
        "gather": {
          "logged": 1747636440708
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a job environment for pipeline steps\n",
        "\n",
        "So far, you've created a development environment on the compute instance, your development machine. You'll also need an [environment](https://docs.microsoft.com/azure/machine-learning/concept-environments) to use for each step of the pipeline. Each step can have its own environment, or you can use some common environments for multiple steps.\n",
        "\n",
        "In this example, you'll create a conda environment for your jobs, using a conda yaml file.\n",
        "First, create a directory to store the file in."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dependencies_dir = \"./dependencies\"\n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "name": "dependencies_dir",
        "gather": {
          "logged": 1747636441585
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now, create the file in the dependencies directory."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_dir}/conda.yaml\n",
        "name: model-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - numpy=1.21.2\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=0.24.2\n",
        "  - scipy=1.7.1\n",
        "  - pandas>=1.1,<1.2\n",
        "  - pip:\n",
        "    - inference-schema[numpy-support]==1.3.0\n",
        "    - xlrd==2.0.1\n",
        "    - azureml-mlflow==1.42.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./dependencies/conda.yaml\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "conda.yaml"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The specification contains some usual packages, that you'll use in your pipeline (numpy, pip).\n",
        "\n",
        "\n",
        "Use the *yaml* file to create and register this custom environment in your workspace:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "custom_env_name = \"aml-scikit-learn\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Credit Card Defaults pipeline\",\n",
        "    tags={\"scikit-learn\": \"0.24.2\"},\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    version=\"0.1.1\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name aml-scikit-learn is registered to workspace, the environment version is 0.1.1\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "custom_env_name",
        "gather": {
          "logged": 1747636446302
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Build the training pipeline\n",
        "\n",
        "Now that you have all assets required to run your pipeline, it's time to build the pipeline itself, using the Azure ML Python SDK v2.\n",
        "\n",
        "Azure ML pipelines are reusable ML workflows that usually consist of several components. The typical life of a component is:\n",
        "\n",
        "* Write the yaml specification of the component.\n",
        "* Optionally, register the component with a name and version in your workspace, to make it reusable and shareable.\n",
        "* Load that component from the pipeline code.\n",
        "* Implement the pipeline using this component inputs, outputs and parameters.\n",
        "* Submit the pipeline.\n",
        "\n",
        "## Create component 1: data prep (using programmatic definition)\n",
        "\n",
        "Let's start by creating the first component. This component handles the preprocessing of the data. The preprocessing task is performed in the *data_prep.py* python file.\n",
        "\n",
        "First create a source folder for the data_prep component:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_prep_src_dir = \"./components/data_prep\"\n",
        "os.makedirs(data_prep_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "data_prep_src_dir",
        "gather": {
          "logged": 1747635646375
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "This script performs the simple task of splitting the data into train and test datasets. \n",
        "\n",
        "[MLFlow](https://mlflow.org/docs/latest/tracking.html) will be used to log the parameters and metrics during our pipeline run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {data_prep_src_dir}/data_prep.py\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "import mlflow\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
        "    parser.add_argument(\"--test_data\", type=str, help=\"path to test data\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.data)\n",
        "\n",
        "    credit_df = pd.read_csv(args.data, header=1, index_col=0)\n",
        "\n",
        "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
        "\n",
        "    credit_train_df, credit_test_df = train_test_split(\n",
        "        credit_df,\n",
        "        test_size=args.test_train_ratio,\n",
        "    )\n",
        "\n",
        "    # output paths are mounted as folder, therefore, we are adding a filename to the path\n",
        "    credit_train_df.to_csv(os.path.join(args.train_data, \"data.csv\"), index=False)\n",
        "\n",
        "    credit_test_df.to_csv(os.path.join(args.test_data, \"data.csv\"), index=False)\n",
        "\n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./components/data_prep/data_prep.py\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "def-main"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now that you have a script that can perform the desired task, we can create an Azure ML Component from it. Azure ML support various types of components for performing ML tasks, such as running scripts, data transfer, etc.\n",
        "\n",
        "A component can be created by calling the component instantiators, or directly writing the defining yaml file. \n",
        "\n",
        "You'll use the general purpose **command** that can run command line actions. This command line action can be directly calling system commands or running a script. The inputs/outputs are accessible in the command via the `${{ ... }}` notation. For the second component of this tutorial you will use `yaml` definitions.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "data_prep_component = command(\n",
        "    name=\"data_prep_credit_defaults\",\n",
        "    display_name=\"Data preparation for training\",\n",
        "    description=\"reads a .xl input, split the input to train and test\",\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_folder\"),\n",
        "        \"test_train_ratio\": Input(type=\"number\"),\n",
        "    },\n",
        "    outputs=dict(\n",
        "        train_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        test_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    ),\n",
        "    # The source folder of the component\n",
        "    code=data_prep_src_dir,\n",
        "    command=\"\"\"python data_prep.py \\\n",
        "            --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} \\\n",
        "            --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "name": "data_prep_component",
        "gather": {
          "logged": 1747636450080
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Optionally, register the component in the workspace for future re-use. **command()** is a component builder, in order to fetch the component itself, we need to call the **.component** property from it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we register the component to the workspace\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component data_prep_credit_defaults with Version 2025-05-19-06-34-14-4379699 is registered\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1747636456075
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create component 2: training (using yaml definition)\n",
        "\n",
        "The second component that you'll create will consume the training and test data, train a tree based model and return the output model. You'll use Azure ML logging capabilities to record and visualize the learning progress.\n",
        "\n",
        "You used the `command` class to create your first component. This time you'll use the yaml definition to define the second component. Each method has its own advantages. A yaml definition can actually be checked-in along the code, and would provide a readable history tracking. Also, the same yaml file can be used in the CLI for component deficnition. The programmatic method using `command` can be easier with built-in class documentation and code completion.\n",
        "\n",
        "\n",
        "Create the directory for this component:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_src_dir = \"./components/train\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "train_src_dir",
        "gather": {
          "logged": 1747635650535
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Create the training script in the directory:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/train.py\n",
        "import argparse\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "\n",
        "\n",
        "def select_first_file(path):\n",
        "    \"\"\"Selects first file in folder, use under assumption there is only one file in folder\n",
        "    Args:\n",
        "        path (str): path to directory or file to choose\n",
        "    Returns:\n",
        "        str: full path of selected file\n",
        "    \"\"\"\n",
        "    files = os.listdir(path)\n",
        "    return os.path.join(path, files[0])\n",
        "\n",
        "\n",
        "# Start Logging\n",
        "mlflow.start_run()\n",
        "\n",
        "# enable autologging\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "os.makedirs(\"./outputs\", exist_ok=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
        "    parser.add_argument(\"--test_data\", type=str, help=\"path to test data\")\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    parser.add_argument(\"--model\", type=str, help=\"path to model file\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # paths are mounted as folder, therefore, we are selecting the file from folder\n",
        "    train_df = pd.read_csv(select_first_file(args.train_data))\n",
        "\n",
        "    # Extracting the label column\n",
        "    y_train = train_df.pop(\"default payment next month\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_train = train_df.values\n",
        "\n",
        "    # paths are mounted as folder, therefore, we are selecting the file from folder\n",
        "    test_df = pd.read_csv(select_first_file(args.test_data))\n",
        "\n",
        "    # Extracting the label column\n",
        "    y_test = test_df.pop(\"default payment next month\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_test = test_df.values\n",
        "\n",
        "    print(f\"Training with data of shape {X_train.shape}\")\n",
        "\n",
        "    clf = GradientBoostingClassifier(\n",
        "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=clf,\n",
        "        registered_model_name=args.registered_model_name,\n",
        "        artifact_path=args.registered_model_name,\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=clf,\n",
        "        path=os.path.join(args.model, \"trained_model\"),\n",
        "    )\n",
        "\n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./components/train/train.py\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "train.py"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "As you can see in this training script, once the model is trained, the model file is saved and registered to the workspace. Now you can use the registered model in inferencing endpoints.\n",
        "\n",
        "\n",
        "For the environment of this step, you'll use one of the built-in (curated) Azure ML environments. The tag `azureml`, tells the system to use look for the name in curated environments.\n",
        "\n",
        "First, create the *yaml* file describing the component:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/train.yml\n",
        "# <component>\n",
        "name: train_credit_defaults_model\n",
        "display_name: Train Credit Defaults Model\n",
        "# version: 1 # Not specifying a version will automatically update the version\n",
        "type: command\n",
        "inputs:\n",
        "  train_data: \n",
        "    type: uri_folder\n",
        "  test_data: \n",
        "    type: uri_folder\n",
        "  learning_rate:\n",
        "    type: number     \n",
        "  registered_model_name:\n",
        "    type: string\n",
        "outputs:\n",
        "  model:\n",
        "    type: uri_folder\n",
        "code: .\n",
        "environment:\n",
        "  # for this step, we'll use an AzureML curate environment\n",
        "  azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
        "command: >-\n",
        "  python train.py \n",
        "  --train_data ${{inputs.train_data}} \n",
        "  --test_data ${{inputs.test_data}} \n",
        "  --learning_rate ${{inputs.learning_rate}}\n",
        "  --registered_model_name ${{inputs.registered_model_name}} \n",
        "  --model ${{outputs.model}}\n",
        "# </component>\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./components/train/train.yml\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "train.yml"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Once the `yaml` file and the script are ready, you can create your component using `load_component()`. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_component = load_component(source=os.path.join(train_src_dir, \"train.yml\"))"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "train_component",
        "gather": {
          "logged": 1747636463217
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now create and register the component:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we register the component to the workspace\n",
        "train_component = ml_client.create_or_update(train_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_component.name} with Version {train_component.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component train_credit_defaults_model with Version 2025-05-19-06-34-28-7885929 is registered\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "update-train_component",
        "gather": {
          "logged": 1747636471102
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create the pipeline from components\n",
        "\n",
        "Now that both your components are defined and registered, you can start implementing the pipeline."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Here, you'll use *input data*, *split ratio* and *registered model name* as input variables. Then call the components and connect them via their inputs /outputs identifiers. The outputs of each step can be accessed via the `.outputs` property."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The python functions returned by `load_component()` work as any regular python function that we'll use within a pipeline to call each step.\n",
        "\n",
        "To code the pipeline, we use a specific `@dsl.pipeline` decorator that identifies the Azure ML pipelines. In the decorator, we can specify the pipeline description and default resources like compute (serverless is used here) and storage. Like a python function, pipelines can have inputs, you can then create multiple instances of a single pipeline with different inputs.\n",
        "\n",
        "Here, we used *input data*, *split ratio* and *registered model name* as input variables. We then call the components and connect them via their inputs /outputs identifiers. The outputs of each step can be accessed via the `.outputs` property."
      ],
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### outputs=dict(\n",
        "    ##### train_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    ##### test_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "##### ),\n",
        "##### train_data: This output will store the training dataset after splitting. Its type=\"uri_folder\" means the output will be written to a folder URI.\n",
        "##### test_data: Similarly, this output will store the testing dataset.\n",
        "##### The mode=\"rw_mount\" specifies how the outputs will be managedâ€”in this case, using read/write mountable storage.\n",
        "##### NOTE: Other valid mode options include:\n",
        "##### \n",
        "##### download: Downloads the data locally.\n",
        "##### upload: Uploads results back to storage after execution."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def credit_defaults_pipeline(\n",
        "    pipeline_job_data_input,\n",
        "    pipeline_job_test_train_ratio,\n",
        "    pipeline_job_learning_rate,\n",
        "    pipeline_job_registered_model_name,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    data_prep_job = data_prep_component(\n",
        "        data=pipeline_job_data_input,\n",
        "        test_train_ratio=pipeline_job_test_train_ratio,\n",
        "    )\n",
        "\n",
        "    # using train_func like a python call with its own inputs\n",
        "    train_job = train_component(\n",
        "        train_data=data_prep_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_prep_job.outputs.test_data,  # note: using outputs from previous step\n",
        "        learning_rate=pipeline_job_learning_rate,  # note: using a pipeline input as parameter\n",
        "        registered_model_name=pipeline_job_registered_model_name,\n",
        "    )\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"pipeline_job_train_data\": data_prep_job.outputs.train_data,\n",
        "        \"pipeline_job_test_data\": data_prep_job.outputs.test_data,\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "pipeline",
        "gather": {
          "logged": 1747636478020
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Now use your pipeline definition to instantiate a pipeline with your dataset, split rate of choice and the name you picked for your model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "registered_model_name = \"credit_defaults_model\"\n",
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "pipeline = credit_defaults_pipeline(\n",
        "    pipeline_job_data_input=Input(type=\"uri_file\", path=credit_data.path),\n",
        "    pipeline_job_test_train_ratio=0.25,\n",
        "    pipeline_job_learning_rate=0.05,\n",
        "    pipeline_job_registered_model_name=registered_model_name,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "registered_model_name",
        "gather": {
          "logged": 1747636483456
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Submit the job \n",
        "\n",
        "It's now time to submit the job to run in Azure ML. This time you'll use `create_or_update`  on `ml_client.jobs`.\n",
        "\n",
        "Here you'll also pass an experiment name. An experiment is a container for all the iterations one does on a certain project. All the jobs submitted under the same experiment name would be listed next to each other in Azure ML studio.\n",
        "\n",
        "Once completed, the pipeline will register a model in your workspace as a result of training."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import webbrowser\n",
        "\n",
        "# submit the pipeline job\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"e2e_registered_components\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(pipeline_job.studio_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "False"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "name": "returned_job",
        "gather": {
          "logged": 1747636489620
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "You can track the progress of your pipeline, by using the link generated in the cell above or in this notebook using the following code:\n",
        "```python\n",
        "    ml_client.jobs.stream(pipeline_job.name)\n",
        "```\n",
        "\n",
        "When you select on each component, you'll see more information about the results of that component. \n",
        "There are two important parts to look for at this stage:\n",
        "* `Outputs+logs` > `user_logs` > `std_log.txt`\n",
        "This section shows the script run sdtout."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "* `Outputs+logs` > `Metric`\n",
        "This section shows different logged metrics. In this example. mlflow `autologging`, has automatically logged the training metrics."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Deploy the model as an online endpoint\n",
        "\n",
        "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
        "\n",
        "To deploy a machine learning service, you usually need:\n",
        "\n",
        "* The model assets (filed, metadata) that you want to deploy. You've already registered these assets in your training component.\n",
        "* Some code to run as a service. The code executes the model on a given input request. This entry script receives data submitted to a deployed web service and passes it to the model, then returns the model's response to the client. The script is specific to your model. The entry script must understand the data that the model expects and returns. When using a MLFlow model, as in this tutorial, this script is automatically created for you. Samples of scoring scripts can be found [here](https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online).\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a new online endpoint\n",
        "\n",
        "Now that you have a registered model and an inference script, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20(UUID,%2C%20for%20practical%20purposes%2C%20unique.)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"credit-endpoint-\" + str(uuid.uuid4())[:8]"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "online_endpoint_name",
        "gather": {
          "logged": 1747636491885
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        ")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is an online endpoint\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"training_dataset\": \"credit_defaults\",\n",
        "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "endpoint_result = ml_client.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(\n",
        "    f\"Endpint {endpoint_result.name} provisioning state: {endpoint_result.provisioning_state}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpint credit-endpoint-13db91f0 provisioning state: Succeeded\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "endpoint",
        "gather": {
          "logged": 1747636592152
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Once you've created an endpoint, you can retrieve it as below:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(\n",
        "    f'Endpint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpint \"credit-endpoint-13db91f0\" with provisioning state \"Succeeded\" is retrieved\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "update-endpoint",
        "gather": {
          "logged": 1747637024627
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Deploy the model to the endpoint\n",
        "\n",
        "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments and direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, *blue*, *green*, *red* deployments, which is arbitrary.\n",
        "\n",
        "You can check the *Models* page on the Azure ML studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick the latest version of the model\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "latest_model_version",
        "gather": {
          "logged": 1747637031930
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Deploy the latest version of the model.  \n",
        "\n",
        "> [!NOTE]\n",
        "> Expect this deployment to take approximately 6 to 8 minutes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "\n",
        "# create an online deployment.\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"STANDARD_D2AS_V4\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment_results = ml_client.online_deployments.begin_create_or_update(\n",
        "    blue_deployment\n",
        ").result()\n",
        "\n",
        "print(\n",
        "    f\"Deployment {blue_deployment_results.name} provisioning state: {blue_deployment_results.provisioning_state}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint credit-endpoint-13db91f0 exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "........................................................................Deployment blue provisioning state: Succeeded\n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "name": "model",
        "gather": {
          "logged": 1747637839294
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Test with a sample query\n",
        "\n",
        "Now that the model is deployed to the endpoint, you can run inference with it.\n",
        "\n",
        "Create a sample request file following the design expected in the run method in the score script."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "name": "sample-request.json",
        "gather": {
          "logged": 1747637953401
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
        "    \"index\": [0, 1],\n",
        "    \"data\": [\n",
        "            [20000,2,2,1,24,2,2,-1,-1,-2,-2,3913,3102,689,0,0,0,0,689,0,0,0,0],\n",
        "            [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8]\n",
        "        ]\n",
        "  }\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./deploy/sample-request.json\n"
        }
      ],
      "execution_count": 64,
      "metadata": {
        "name": "write-sample-request"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test the blue deployment with some sample data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_endpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monline_endpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deploy/sample-request.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:138\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    137\u001b[0m                 span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:288\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(ACTIVITY_SPAN):\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    286\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    287\u001b[0m         ):\n\u001b[0;32m--> 288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:365\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.invoke\u001b[0;34m(self, endpoint_name, request_file, deployment_name, input_data, params_override, local, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deployment_name:\n\u001b[1;32m    363\u001b[0m     headers[EndpointInvokeFields\u001b[38;5;241m.\u001b[39mMODEL_DEPLOYMENT] \u001b[38;5;241m=\u001b[39m deployment_name\n\u001b[0;32m--> 365\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m validate_response(response)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext())\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_http_utils.py:68\u001b[0m, in \u001b[0;36m_request_function.<locals>._.<locals>.decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A function that sends an HTTP request and returns the response.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mAccepts the same parameters as azure.core.rest.HttpRequest, except for the method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m:rtype: HttpResponse\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m request \u001b[38;5;241m=\u001b[39m HttpRequest(\n\u001b[1;32m     58\u001b[0m     f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     files\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhttp_response\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:242\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m pipeline_request: PipelineRequest[HTTPRequestType] \u001b[38;5;241m=\u001b[39m PipelineRequest(request, context)\n\u001b[1;32m    241\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport)\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfirst_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_request\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/policies/_redirect.py:205\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    203\u001b[0m original_domain \u001b[38;5;241m=\u001b[39m get_domain(request\u001b[38;5;241m.\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl) \u001b[38;5;28;01mif\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[0;32m--> 205\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     redirect_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_redirect_location(response)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m redirect_location \u001b[38;5;129;01mand\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/policies/_retry.py:544\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[1;32m    543\u001b[0m request\u001b[38;5;241m.\u001b[39mcontext[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(retry_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 544\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_retry(retry_settings, response):\n\u001b[1;32m    546\u001b[0m     retry_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincrement(retry_settings, response\u001b[38;5;241m=\u001b[39mresponse)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/_base.py:130\u001b[0m, in \u001b[0;36m_TransportRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"HTTP transport send method.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m:param request: The PipelineRequest object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m:rtype: ~azure.core.pipeline.PipelineResponse\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m cleanup_kwargs_for_transport(request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PipelineResponse(\n\u001b[1;32m    129\u001b[0m     request\u001b[38;5;241m.\u001b[39mhttp_request,\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    131\u001b[0m     context\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mcontext,\n\u001b[1;32m    132\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/pipeline/transport/_requests_basic.py:363\u001b[0m, in \u001b[0;36mRequestsTransport.send\u001b[0;34m(self, request, proxies, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         read_timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_config\u001b[38;5;241m.\u001b[39mread_timeout)\n\u001b[1;32m    362\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m (connection_timeout, read_timeout)\n\u001b[0;32m--> 363\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconnection_verify\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconnection_cert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m     response\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39menforce_content_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/opentelemetry/instrumentation/requests/__init__.py:210\u001b[0m, in \u001b[0;36m_instrument.<locals>.instrumented_send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request\u001b[38;5;241m.\u001b[39mheaders\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_http_instrumentation_enabled():\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_send\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# See\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# https://github.com/open-telemetry/semantic-conventions/blob/main/docs/http/http-spans.md#http-client\u001b[39;00m\n\u001b[1;32m    214\u001b[0m method \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mmethod\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/opentelemetry/instrumentation/urllib3/__init__.py:325\u001b[0m, in \u001b[0;36m_instrument.<locals>.instrumented_urlopen\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minstrumented_urlopen\u001b[39m(wrapped, instance, args, kwargs):\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_http_instrumentation_enabled():\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     url \u001b[38;5;241m=\u001b[39m _get_url(instance, args, kwargs, url_filter)\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m excluded_urls \u001b[38;5;129;01mand\u001b[39;00m excluded_urls\u001b[38;5;241m.\u001b[39murl_disabled(url):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 65,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "ml_client.online_endpoints.invoke",
        "gather": {
          "logged": 1747639090399
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=\"credit-endpoint-13db91f0\")\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\nReadonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 63,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7c2b47e298a0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1747638900518
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=\"credit-endpoint-13db91f0\")\n",
        "print(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "auth_mode: key\ndescription: this is an online endpoint\nid: /subscriptions/fdec3bff-d6e2-4cf8-87b9-8439c441c1b7/resourceGroups/DP100/providers/Microsoft.MachineLearningServices/workspaces/dp100demo/onlineEndpoints/credit-endpoint-13db91f0\nidentity:\n  principal_id: 3634c157-ba51-4e8f-8172-e8c76119257e\n  tenant_id: b41b72d0-4e9f-4c26-8a69-f949f367c91d\n  type: system_assigned\nkind: Managed\nlocation: centralindia\nmirror_traffic: {}\nname: credit-endpoint-13db91f0\nopenapi_uri: https://credit-endpoint-13db91f0.centralindia.inference.ml.azure.com/swagger.json\nproperties:\n  AzureAsyncOperationUri: https://management.azure.com/subscriptions/fdec3bff-d6e2-4cf8-87b9-8439c441c1b7/providers/Microsoft.MachineLearningServices/locations/centralindia/mfeOperationsStatus/oeidp:b1fa3f7a-f521-409b-a1c1-234606990ad5:f6e513e6-4a61-4e0a-9aa3-e1a87897e06a?api-version=2022-02-01-preview\n  azureml.onlineendpointid: /subscriptions/fdec3bff-d6e2-4cf8-87b9-8439c441c1b7/resourcegroups/dp100/providers/microsoft.machinelearningservices/workspaces/dp100demo/onlineendpoints/credit-endpoint-13db91f0\n  createdAt: 2025-05-19T06:34:59.763438+0000\n  createdBy: Virendra Rathore\n  lastModifiedAt: 2025-05-19T06:34:59.763438+0000\nprovisioning_state: Succeeded\npublic_network_access: enabled\nscoring_uri: https://credit-endpoint-13db91f0.centralindia.inference.ml.azure.com/score\ntags:\n  model_type: sklearn.GradientBoostingClassifier\n  training_dataset: credit_defaults\ntraffic:\n  blue: 0\n\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1747638023726
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace with your actual scoring URI and key\n",
        "scoring_uri = \"https://credit-endpoint-13db91f0.centralindia.inference.ml.azure.com/score\"\n",
        "key = \"4uzDC0fx22WRNpdKcYtI5FavJmivR653YNyTQ0zVNROjcObwRUijJQQJ99BEAAAAAAAAAAAAINFRAZML1xjb\"\n",
        "\n",
        "# Sample input data\n",
        "data = {\n",
        "  \"input_data\": {\n",
        "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
        "    \"index\": [0, 1],\n",
        "    \"data\": [\n",
        "            [20000,222,22222,221,24,2,2,-1,-1,-2,-2,3913,3102,689,1000,0,1000,0,689,0,0,0,0],\n",
        "            [10, 9, 8, 79, 6, 5, 4, 3, 2, 1, 10, 9, 8, 74, 6, 5, 4, 3, 2, 1, 10, 9, 8]\n",
        "        ]\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Set the headers\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {key}\"\n",
        "}\n",
        "\n",
        "# Send the POST request\n",
        "response = requests.post(scoring_uri, headers=headers, data=json.dumps(data))\n",
        "\n",
        "# Print the response\n",
        "print(\"Response status code:\", response.status_code)\n",
        "print(\"Response body:\", response.json())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Response status code: 200\nResponse body: [0, 0]\n"
        }
      ],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1747639175120
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Clean up resources\n",
        "\n",
        "If you're not going to use the endpoint, delete it to stop using the resource.  Make sure no other deployments are using an endpoint before you delete it.\n",
        "\n",
        "\n",
        "> [!NOTE]\n",
        "> Expect this step to take approximately 6 to 8 minutes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7a158674f100>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "................................................................"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "attributes": {
          "classes": [
            "python "
          ],
          "id": ""
        },
        "name": "ml_client.online_endpoints.begin_delete",
        "gather": {
          "logged": 1747630645688
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "Learn more about [Azure ML logging](https://github.com/Azure/azureml-examples/blob/sdk-preview/notebooks/mlflow/mlflow-v1-comparison.ipynb)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "vscode": {
      "interpreter": {
        "hash": "78d13900fb236b5ce4c0b952de9b1270f1802c447ee20a989ea10ffd935aa825"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "celltoolbar": "Edit Metadata",
    "categories": [
      "SDK v2",
      "tutorials"
    ],
    "description": {
      "description": "Create production ML pipelines with Python SDK v2 in a Jupyter notebook"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}